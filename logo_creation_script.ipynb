{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DinoJourney Logo Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook was used to generate the images used in our ShellHacks 2024 Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "S_3WP-trBI0u"
   },
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML\n",
    "import replicate\n",
    "import time\n",
    "import json\n",
    "from PIL import Image as PilImage, ImageDraw, ImageFont\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import os\n",
    "from getpass import getpass\n",
    "import matplotlib.pyplot as plt\n",
    "import httpx\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Lb4SsIcSCs1b",
    "outputId": "3acee921-a5fc-4a9f-9511-fd04c8a85d61"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "# get your API Key from Replicate website and paste it here.\n",
    "REPLICATE_API_TOKEN = getpass()\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = REPLICATE_API_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "nMwAgcAfMYHG"
   },
   "outputs": [],
   "source": [
    "def replicate_run(model, prompt, num_images):\n",
    "    title = model.split(':')[0]\n",
    "\n",
    "    # Set the API key using environment variable\n",
    "    api_token = os.getenv(\"REPLICATE_API_TOKEN\")  # Ensure API key is set\n",
    "    if not api_token:\n",
    "        raise ValueError(\"API token not found or is empty\")\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {api_token}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    # Define the payload (you may need to adjust this based on the model's input schema)\n",
    "    data = {\n",
    "        \"version\": model.split(\":\")[1],\n",
    "        \"input\": {\n",
    "            \"prompt\": prompt,\n",
    "            \"num_outputs\": num_images\n",
    "            # Add more parameters here depending on the model's schema (e.g., guidance_scale, controlnet, etc.)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Measure time taken for API call\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        # Make the POST request to start the prediction\n",
    "        response = httpx.post(\"https://api.replicate.com/v1/predictions\", headers=headers, json=data)\n",
    "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
    "        response_json = response.json()\n",
    "    except httpx.HTTPStatusError as e:\n",
    "        print(f\"HTTP error occurred: {e.response.status_code} - {e.response.text}\")\n",
    "        return None, title, 0, 0\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return None, title, 0, 0\n",
    "    \n",
    "    # Extract the prediction URL for polling\n",
    "    prediction_url = response_json.get(\"urls\", {}).get(\"get\")\n",
    "    if not prediction_url:\n",
    "        raise ValueError(\"Could not retrieve prediction URL\")\n",
    "\n",
    "    print(f\"Prediction started, polling at: {prediction_url}\")\n",
    "\n",
    "    # Poll the result until the status is 'succeeded'\n",
    "    def poll_prediction(url, headers, interval=5):\n",
    "        while True:\n",
    "            response = httpx.get(url, headers=headers)\n",
    "            result = response.json()\n",
    "\n",
    "            # Check if the status is complete\n",
    "            status = result.get(\"status\")\n",
    "            if status == \"succeeded\":\n",
    "                return result.get(\"output\")\n",
    "            elif status == \"failed\":\n",
    "                raise Exception(\"Prediction failed\")\n",
    "\n",
    "            # Print the status every poll\n",
    "            print(f\"Prediction status: {status}, retrying in {interval} seconds...\")\n",
    "            time.sleep(interval)\n",
    "\n",
    "    # Poll for the output dynamically\n",
    "    try:\n",
    "        output = poll_prediction(prediction_url, headers)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during polling: {str(e)}\")\n",
    "        return None, title, 0, 0\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    average_time = total_time / num_images\n",
    "\n",
    "    return output, title, total_time, average_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJQCXjA3MIdt"
   },
   "source": [
    "Enter your prompt below and run the cell! Note it might take some time for all images to generate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with multiple text-to-image-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research work to be presented next month at HCOMP shows that side-by-side text-to-image AI models can help users identify model styles more easily. \n",
    "\n",
    "We take advantage of this by generating images from **different models** using the **same prompt,** allowing us to narrow down which models we would like to proceed with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "CLkqvoT7xGXV"
   },
   "outputs": [],
   "source": [
    "def display_4x4_grid(outputs):\n",
    "    fig, axs = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    fig.suptitle(\"4x4 Model Output Gallery\", fontsize=16)\n",
    "\n",
    "    for i, (model_output, title, total_time, average_time) in enumerate(outputs[:16]):\n",
    "        # Select the first image for each model\n",
    "        image_url = model_output[0]\n",
    "        response = requests.get(image_url)\n",
    "        img = PilImage.open(BytesIO(response.content))\n",
    "\n",
    "        axs[i//4, i%4].imshow(img)\n",
    "        axs[i//4, i%4].set_title(f\"{title[:]}\\n{total_time:.2f}s\")\n",
    "        axs[i//4, i%4].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "L015CvLRKcgF",
    "outputId": "c31a10a3-5584-451a-fe34-517f8cfe6029",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 19 other models that you can pick from\n",
    "outputs = []\n",
    "prompt, num = \"A cute green magnifying glass\", 1\n",
    "\n",
    "outputs.append(replicate_run(\"lucataco/ssd-1b:b19e3639452c59ce8295b82aba70a231404cb062f2eb580ea894b31e8ce5bbb6\", prompt, num))\n",
    "outputs.append(replicate_run(\"playgroundai/playground-v2.5-1024px-aesthetic:a45f82a1382bed5c7aeb861dac7c7d191b0fdf74d8d57c4a0e6ed7d4d0bf7d24\", prompt, num))\n",
    "outputs.append(replicate_run(\"fofr/realvisxl-v3-multi-controlnet-lora:90a4a3604cd637cb9f1a2bdae1cfa9ed869362ca028814cdce310a78e27daade\", prompt, num))\n",
    "outputs.append(replicate_run(\"fofr/sticker-maker:4acb778eb059772225ec213948f0660867b2e03f277448f18cf1800b96a65a1a\", prompt, num))\n",
    "\n",
    "outputs.append(replicate_run(\"lucataco/realvisxl2-lcm:479633443fc6588e1e8ae764b79cdb3702d0c196e0cb2de6db39ce577383be77\", prompt, num))\n",
    "outputs.append(replicate_run(\"playgroundai/playground-v2-1024px-aesthetic:42fe626e41cc811eaf02c94b892774839268ce1994ea778eba97103fe1ef51b8\", prompt, num))\n",
    "outputs.append(replicate_run(\"lucataco/realvisxl-v2.0:7d6a2f9c4754477b12c14ed2a58f89bb85128edcdd581d24ce58b6926029de08\", prompt, num))\n",
    "outputs.append(replicate_run(\"fofr/sdxl-multi-controlnet-lora:89eb212b3d1366a83e949c12a4b45dfe6b6b313b594cb8268e864931ac9ffb16\", prompt, num))\n",
    "\n",
    "outputs.append(replicate_run(\"lucataco/dreamshaper-xl-turbo:0a1710e0187b01a255302738ca0158ff02a22f4638679533e111082f9dd1b615\", prompt, num))\n",
    "outputs.append(replicate_run(\"lucataco/open-dalle-v1.1:1c7d4c8dec39c7306df7794b28419078cb9d18b9213ab1c21fdc46a1deca0144\", prompt, num))\n",
    "outputs.append(replicate_run(\"ai-forever/kandinsky-2-1:a768f3c2e174c54b576cc4f222e789e161160403d0cd0ace41eeb9a0f8c8d5f8\", prompt, num))\n",
    "outputs.append(replicate_run(\"adirik/realvisxl-v3.0-turbo:3dc73c805b11b4b01a60555e532fd3ab3f0e60d26f6584d9b8ba7e1b95858243\", prompt, num))\n",
    "\n",
    "outputs.append(replicate_run(\"lucataco/pixart-xl-2:816c99673841b9448bc2539834c16d40e0315bbf92fef0317b57a226727409bb\", prompt, num))\n",
    "outputs.append(replicate_run(\"adirik/realvisxl-v4.0:85a58cc71587cc27539b7c83eb1ce4aea02feedfb9a9fae0598cebc110a3d695\", prompt, num))\n",
    "outputs.append(replicate_run(\"lucataco/proteus-v0.3:b28b79d725c8548b173b6a19ff9bffd16b9b80df5b18b8dc5cb9e1ee471bfa48\", prompt, num))\n",
    "outputs.append(replicate_run(\"lucataco/thinkdiffusionxl:c41c12756b561bc81047a9307c9143589d158ef084655dbb3073b4f08ff54f32\", prompt, num))\n",
    "\n",
    "outputs.append(replicate_run(\"artificialguybr/nebul.redmond:1abd2490609ffab31652791c065fa2da180053b77fe0ed0e7e879460bf549d33\", prompt, num))\n",
    "outputs.append(replicate_run(\"fofr/txt2img:18f1d88376233fef85e7289d65326b9ceabd3a78215a6833bfb7775792f42b79\", prompt, num))\n",
    "outputs.append(replicate_run(\"lucataco/sdxl-deepcache:eaf678fb34006669e9a3c6dd5971e2279bf20ee0adeced464d7b6d95de16dc93\", prompt, num))\n",
    "\n",
    "display_4x4_grid(outputs[-3]) # not displaying the last 3 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with a single text-to-image model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the initial analysis above, \"bytedance/sdxl-lightining-4step\" was chosen due to its speed and quality.\n",
    "\n",
    "Additionally, its generated images aligned closely with what our team envisioned when we prompted for a \"simplistic and cartoonish\" image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have one model we will be working with, we will try different prompts to gauge which prompt produces the best image for our needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "background_save": true,
     "referenced_widgets": [
      "d51aa25a78cb4d2f871f111b0aee5920"
     ]
    },
    "id": "6OpEVl9uETI2",
    "outputId": "031b3930-49a1-4451-92b4-7b7e532ea163"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction started, polling at: https://api.replicate.com/v1/predictions/1jycgfyznhrj20cj6wgsy7eqfg\n",
      "Prediction status: starting, retrying in 5 seconds...\n",
      "Prediction started, polling at: https://api.replicate.com/v1/predictions/15cem47ws9rj60cj6wgthpj6cc\n",
      "Prediction status: processing, retrying in 5 seconds...\n",
      "Prediction started, polling at: https://api.replicate.com/v1/predictions/qkg5wz8t71rj60cj6whbs3be7r\n",
      "Prediction status: processing, retrying in 5 seconds...\n",
      "Prediction started, polling at: https://api.replicate.com/v1/predictions/k7wnr1stjxrj00cj6whaxz7d80\n",
      "Prediction status: processing, retrying in 5 seconds...\n",
      "Prediction started, polling at: https://api.replicate.com/v1/predictions/80n1hbjt85rj00cj6wh8418axg\n",
      "Prediction status: processing, retrying in 5 seconds...\n",
      "Prediction started, polling at: https://api.replicate.com/v1/predictions/mg1hqd3pyhrj40cj6wh8v37pvw\n",
      "Prediction status: processing, retrying in 5 seconds...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49cb5221533e4e52a8ca513699e62cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<b>bytedance/sdxl-lightning-4step</b><br>Total Time: 7.63s<br>Avg Ti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stored generated images\n",
    "outputs = []\n",
    "\n",
    "# note that number of generated images per model must be <= 4\n",
    "prompt, num = \"A cute and happy green magnifying glass\", 4\n",
    "outputs.append(replicate_run(\"bytedance/sdxl-lightning-4step:727e49a643e999d602a896c774a0658ffefea21465756a6ce24b7ea4165eba6a\", prompt, num))\n",
    "\n",
    "prompt, num = \"A green magnifying glass\", 4\n",
    "outputs.append(replicate_run(\"bytedance/sdxl-lightning-4step:727e49a643e999d602a896c774a0658ffefea21465756a6ce24b7ea4165eba6a\", prompt, num))\n",
    "\n",
    "prompt, num = \"A nice green magnifying glass\", 4\n",
    "outputs.append(replicate_run(\"bytedance/sdxl-lightning-4step:727e49a643e999d602a896c774a0658ffefea21465756a6ce24b7ea4165eba6a\", prompt, num))\n",
    "\n",
    "prompt, num = \"An awesome green magnifying glass\", 4\n",
    "outputs.append(replicate_run(\"bytedance/sdxl-lightning-4step:727e49a643e999d602a896c774a0658ffefea21465756a6ce24b7ea4165eba6a\", prompt, num))\n",
    "\n",
    "prompt, num = \"A happy little cartoonish man\", 4\n",
    "outputs.append(replicate_run(\"bytedance/sdxl-lightning-4step:727e49a643e999d602a896c774a0658ffefea21465756a6ce24b7ea4165eba6a\", prompt, num))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get your API Key from Replicate website and paste it here.\n",
    "OPEN_AI_KEY = getpass()\n",
    "os.environ[\"OPEN_AI_KEY\"] = OPEN_AI_KEY\n",
    "\n",
    "response = openai.Image.create(\n",
    "    prompt=\"A cute happy magnifying glass cartoonish\",\n",
    "    n=1,\n",
    "    size=\"256x256\"\n",
    ")\n",
    "\n",
    "# The response includes a list of generated image URLs\n",
    "image_url = response[\"data\"][0][\"url\"]\n",
    "print(image_url)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Logo Creation Kernel",
   "language": "python",
   "name": "logos_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
