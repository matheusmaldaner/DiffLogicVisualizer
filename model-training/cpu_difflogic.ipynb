{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad547e88-45bb-401b-818e-dcb83ce96697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PyTorch Utilities\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from tqdm import tqdm  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ed907f-0447-4440-9955-77fd46d0883b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Dataset stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "327b6588-b309-4843-a454-9e7c8c82d9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/blue/woodard/mkunzlermaldaner/EXPLOGIC/explogic_env/lib/python3.9/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Train Dataset Size: 54210\n",
      "Balanced Test Dataset Size: 8920\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from utils import dataset_getter as dat\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dataset and Preprocessing Settings\n",
    "crop = (20,20)  # Cropping configuration: None removes no border, specify (x,x) for cropping dimensions\n",
    "\n",
    "# Dataset Selection\n",
    "# Options: \"mnist\" or \"fashion_mnist\"\n",
    "dataset_name = \"mnist\"\n",
    "\n",
    "# Bits Per Pixel (Fixed at 1 for binary data in ExpLogic)\n",
    "bpp = 1\n",
    "\n",
    "# Ensuring Reproducibility Across Runs\n",
    "# Seeds for Random Generators in PyTorch, NumPy, and Python\n",
    "seed_value = 42\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)\n",
    "\n",
    "# DataLoader Parameters\n",
    "batch_size = 512\n",
    "train_loader, test_loader, input_dim, out_dim = dat.get_dataset(\n",
    "    dataset_name, batch_size=batch_size, data_dir=\"./data\", bpp=bpp, crop=crop\n",
    ")\n",
    "\n",
    "# Analyze and Balance Class Distribution in Dataset\n",
    "train_targets = train_loader.dataset.targets\n",
    "test_targets = test_loader.dataset.targets\n",
    "\n",
    "# Class-Wise Sample Count\n",
    "train_class_counts = [torch.sum(train_targets == i).item() for i in range(10)]\n",
    "test_class_counts = [torch.sum(test_targets == i).item() for i in range(10)]\n",
    "\n",
    "# Determine Minimum Samples Per Class for Balanced Dataset\n",
    "min_samples_train = min(train_class_counts)\n",
    "min_samples_test = min(test_class_counts)\n",
    "\n",
    "# Define Function to Trim Datasets for Balance\n",
    "def balance_dataset(dataset, targets, min_samples):\n",
    "    indices = []\n",
    "    for class_label in range(10):\n",
    "        class_indices = (targets == class_label).nonzero(as_tuple=True)[0]\n",
    "        indices.extend(class_indices[:min_samples])\n",
    "\n",
    "    # Shuffle Indices to Randomize the Dataset\n",
    "    indices = torch.tensor(indices)\n",
    "    shuffled_indices = indices[torch.randperm(indices.size(0))]\n",
    "    \n",
    "    return Subset(dataset, shuffled_indices)\n",
    "\n",
    "# Apply Balancing to Train and Test Datasets\n",
    "balanced_train_dataset = balance_dataset(train_loader.dataset, train_targets, min_samples_train)\n",
    "balanced_test_dataset = balance_dataset(test_loader.dataset, test_targets, min_samples_test)\n",
    "\n",
    "# Re-Initialize DataLoaders with Balanced Datasets\n",
    "train_loader_balanced = DataLoader(\n",
    "    balanced_train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last=True\n",
    ")\n",
    "test_loader_balanced = DataLoader(\n",
    "    balanced_test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, drop_last=True\n",
    ")\n",
    "\n",
    "# Verify New Dataset Sizes\n",
    "print(f\"Balanced Train Dataset Size: {len(train_loader_balanced.dataset)}\")\n",
    "print(f\"Balanced Test Dataset Size: {len(test_loader_balanced.dataset)}\")\n",
    "\n",
    "# Update Loaders and Datasets for Subsequent Use\n",
    "train_loader = train_loader_balanced\n",
    "test_loader = test_loader_balanced\n",
    "\n",
    "# Visualize a Random Image from the Balanced Training Dataset\n",
    "data_index = random.randint(0, len(train_loader.dataset) - 1)\n",
    "random_image, _ = train_loader.dataset[data_index]\n",
    "\n",
    "# Process Image for Display\n",
    "image_shape = (20, 20) if crop else (28, 28)\n",
    "processed_image = np.array([\n",
    "    np.sum([random_image[(i * bpp) + j] * (2 ** (bpp - j + 1)) for j in range(bpp)])\n",
    "    for i in range(image_shape[0] * image_shape[0])\n",
    "]).reshape(image_shape)\n",
    "\n",
    "# Plot the Processed Image\n",
    "plt.figure()\n",
    "plt.imshow(processed_image, cmap=\"gray\")\n",
    "plt.title(\"Sample Image from Balanced Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7660348a-c21c-46b2-89d4-7f7612c92ba4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### CPU Based Logic Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3eb6dc7-1ebd-4ea9-8bd1-60e406111541",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LogicLayer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The core module for differentiable logic gate networks. Provides a differentiable logic gate layer.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim: int,\n",
    "            out_dim: int,\n",
    "            device: str = 'cpu',\n",
    "            grad_factor: float = 1.,\n",
    "            implementation: str = 'cpu',\n",
    "            connections: str = 'random',\n",
    "    ):\n",
    "        \"\"\"\n",
    "        :param in_dim:      input dimensionality of the layer\n",
    "        :param out_dim:     output dimensionality of the layer\n",
    "        :param device:      device (options: 'cpu')\n",
    "        :param grad_factor: for deep models (>6 layers), the grad_factor should be increased (e.g., 2) to avoid vanishing gradients\n",
    "        :param implementation: implementation to use (options: 'python').\n",
    "        :param connections: method for initializing the connectivity of the logic gate net\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.weights = torch.nn.parameter.Parameter(torch.randn(out_dim, 16, device=device))\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.device = device\n",
    "        self.grad_factor = grad_factor\n",
    "\n",
    "        # forces implementation to be python and use cpu\n",
    "        self.implementation = 'python'\n",
    "        #self.implementation = implementation\n",
    "  \n",
    "        if self.implementation is None and device == 'cpu':\n",
    "            self.implementation = 'python'\n",
    "        assert self.implementation in ['python'], self.implementation\n",
    "\n",
    "        self.connections = connections\n",
    "        assert self.connections in ['random', 'unique'], self.connections\n",
    "        self.indices = self.get_connections(self.connections, device)\n",
    "\n",
    "        self.num_neurons = out_dim\n",
    "        self.num_weights = out_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.implementation == 'python':\n",
    "            return self.forward_python(x)\n",
    "        else:\n",
    "            raise ValueError(self.implementation)\n",
    "\n",
    "    def forward_python(self, x):\n",
    "        assert x.shape[-1] == self.in_dim, (x[0].shape[-1], self.in_dim)\n",
    "\n",
    "        if self.indices[0].dtype == torch.int64 or self.indices[1].dtype == torch.int64:            \n",
    "            self.indices = self.indices[0].long(), self.indices[1].long()   \n",
    "\n",
    "        a, b = x[..., self.indices[0]], x[..., self.indices[1]]\n",
    "        if self.training:\n",
    "            x = bin_op_s(a, b, torch.nn.functional.softmax(self.weights, dim=-1))\n",
    "        else:\n",
    "            weights = torch.nn.functional.one_hot(self.weights.argmax(-1), 16).to(torch.float32)\n",
    "            x = bin_op_s(a, b, weights)\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return '{}, {}, {}'.format(self.in_dim, self.out_dim, 'train' if self.training else 'eval')\n",
    "\n",
    "    def get_connections(self, connections, device='cpu'):\n",
    "        assert self.out_dim * 2 >= self.in_dim, 'The number of neurons ({}) must not be smaller than half of the ' \\\n",
    "                                                'number of inputs ({}) because otherwise not all inputs could be ' \\\n",
    "                                                'used or considered.'.format(self.out_dim, self.in_dim)\n",
    "        if connections == 'random':\n",
    "            c = torch.randperm(2 * self.out_dim) % self.in_dim\n",
    "            c = torch.randperm(self.in_dim)[c]\n",
    "            c = c.reshape(2, self.out_dim)\n",
    "            a, b = c[0], c[1]\n",
    "            a, b = a.to(torch.int64), b.to(torch.int64)\n",
    "            a, b = a.to(device), b.to(device)\n",
    "            return a, b\n",
    "        elif connections == 'unique':\n",
    "            return get_unique_connections(self.in_dim, self.out_dim, device)\n",
    "        else:\n",
    "            raise ValueError(connections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a624075e-f28d-4cdd-8b88-3cad8d6822f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### CPU Bin Op S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d444dd-3931-4d15-b7ec-d885dc904fbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bin_op(a, b, i):\n",
    "    assert a[0].shape == b[0].shape, (a[0].shape, b[0].shape)\n",
    "    if a.shape[0] > 1:\n",
    "        assert a[1].shape == b[1].shape, (a[1].shape, b[1].shape)\n",
    "\n",
    "    if i == 0:\n",
    "        return torch.zeros_like(a)\n",
    "    elif i == 1:\n",
    "        return a * b\n",
    "    elif i == 2:\n",
    "        return a - a * b\n",
    "    elif i == 3:\n",
    "        return a\n",
    "    elif i == 4:\n",
    "        return b - a * b\n",
    "    elif i == 5:\n",
    "        return b\n",
    "    elif i == 6:\n",
    "        return a + b - 2 * a * b\n",
    "    elif i == 7:\n",
    "        return a + b - a * b\n",
    "    elif i == 8:\n",
    "        return 1 - (a + b - a * b)\n",
    "    elif i == 9:\n",
    "        return 1 - (a + b - 2 * a * b)\n",
    "    elif i == 10:\n",
    "        return 1 - b\n",
    "    elif i == 11:\n",
    "        return 1 - b + a * b\n",
    "    elif i == 12:\n",
    "        return 1 - a\n",
    "    elif i == 13:\n",
    "        return 1 - a + a * b\n",
    "    elif i == 14:\n",
    "        return 1 - a * b\n",
    "    elif i == 15:\n",
    "        return torch.ones_like(a)\n",
    "\n",
    "def bin_op_s(a, b, i_s):\n",
    "    device = 'cpu'\n",
    "    b = b.to(device)\n",
    "    i_s = i_s.to(device)\n",
    "\n",
    "    r = torch.zeros_like(a, device=device)\n",
    "    for i in range(16):\n",
    "        u = bin_op(a, b, i)\n",
    "        r = r + i_s[..., i] * u\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee553360-1de5-4d40-8ccc-6e65a3e02114",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### CPU Based GroupSum function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a91561e9-275b-40b5-9b3d-061e16abd515",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GroupSum(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The GroupSum module.\n",
    "    \"\"\"\n",
    "    def __init__(self, k: int, tau: float = 1., device='cpu'):\n",
    "        \"\"\"\n",
    "        :param k: number of intended real valued outputs, e.g., number of classes\n",
    "        :param tau: the (softmax) temperature tau. The summed outputs are divided by tau.\n",
    "        :param device: cpu\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.k = k\n",
    "        self.tau = tau\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.shape[-1] % self.k == 0, (x.shape, self.k)\n",
    "        return x.reshape(*x.shape[:-1], self.k, x.shape[-1] // self.k).sum(-1) / self.tau\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return 'k={}, tau={}'.format(self.k, self.tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bf6022-4a7d-49e7-904c-cffd24fc246c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### CPU Based DiffLogic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e1c9fc8-7d85-421a-be24-0c50ae01bfc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DiffLogic(nn.Module):\n",
    "    def __init__(self, layers_config, output_size, tau=30):\n",
    "        \"\"\"\n",
    "        Initializes the DiffLogic model with the specified layer configurations, output size, and temperature parameter.\n",
    "\n",
    "        Args:\n",
    "            layers_config (dict): Configuration for each logic layer, including dimensions, device, implementation, connections, and grad factor.\n",
    "            output_size (int): The number of output groups (classes in a classification problem).\n",
    "            tau (int): Temperature parameter for the GroupSum operation.\n",
    "        \"\"\"\n",
    "        super(DiffLogic, self).__init__()\n",
    "        \n",
    "        # stores the logic layers\n",
    "        layers = []\n",
    "        for layer_name, config in layers_config.items():\n",
    "            layer = LogicLayer(\n",
    "                in_dim=config['in_dim'],\n",
    "                out_dim=config['out_dim'],\n",
    "                device=config['device'],\n",
    "                implementation=config['implementation'],\n",
    "                connections=config['connections'],\n",
    "                grad_factor=config['grad_factor']       \n",
    "            )\n",
    "            layers.append(layer)\n",
    "            print(layer)\n",
    "        \n",
    "        self.logic_layers = nn.Sequential(*layers)\n",
    "        self.group = GroupSum(k=output_size, tau=tau)\n",
    "        self.log_text = \"\"  # initializes logging string\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the DiffLogic model.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor after processing through the logic layers and grouping operation.\n",
    "        \"\"\"        \n",
    "        logits = self.logic_layers(x)\n",
    "        group = self.group(logits)\n",
    "        return group\n",
    "    \n",
    "    def save(self, file_path, model_name='model', model_cfg=None):\n",
    "        \"\"\"\n",
    "        Saves the model's state dictionary plus all relevant architecture info\n",
    "        to the specified file path.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path where the model will be saved.\n",
    "            model_name (str): Name of the saved model.\n",
    "            model_cfg (dict): The full dictionary that contains layer config,\n",
    "                              output_size, tau, learning rate, etc.\n",
    "        \"\"\"\n",
    "        checkpoint_data = {\n",
    "            'model_state_dict': self.state_dict(),\n",
    "            'connections': [\n",
    "                layer.indices \n",
    "                for layer in self.logic_layers \n",
    "                if isinstance(layer, LogicLayer)\n",
    "            ],\n",
    "            # Store the entire config so you can reconstruct everything\n",
    "            'model_config': {\n",
    "                'layers_config': model_cfg['layers_config'],\n",
    "                'output_size': model_cfg['output_size'],\n",
    "                'tau': model_cfg['tau'],\n",
    "                'learning_rate': model_cfg.get('learning_rate', None),\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Now dump that all out to disk\n",
    "        torch.save(checkpoint_data, os.path.join(file_path, f\"{model_name}.pth\"))\n",
    "        self.log_text += f\"Model saved to: {file_path}\\n\"\n",
    "\n",
    "\n",
    "    def load(self, file_path):\n",
    "        \"\"\"\n",
    "        Loads the model's state dictionary from the specified file path.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path from which the model will be loaded.\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        checkpoint = torch.load(file_path)\n",
    "        self.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "        # assigns connections to each LogicLayer\n",
    "        for idx, layer in enumerate(self.logic_layers):\n",
    "            if isinstance(layer, LogicLayer):\n",
    "                layer.indices = checkpoint['connections'][idx]\n",
    "\n",
    "        self.eval()\n",
    "        self.log_text += f\"Model loaded from: {file_path}\\n\"\n",
    "     \n",
    "    def get_accuracy(self, data_loader):\n",
    "        \"\"\"\n",
    "        Calculates the accuracy of the model against a data loader\n",
    "\n",
    "        Args:\n",
    "            data_loader: a DataLoader object, e.g. train_loader or test_loader\n",
    "\n",
    "        Returns:\n",
    "            float: The accuracy\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        # ensures that model is in evaluation mode\n",
    "        self.eval()\n",
    "\n",
    "        with torch.no_grad():  # Disable gradient calculation for inference\n",
    "            for batch_inputs, batch_outputs in tqdm(data_loader, desc=\"Running Inference\"):\n",
    "                batch_inputs, batch_outputs = batch_inputs.to('cpu'), batch_outputs.to('cpu')\n",
    "\n",
    "                # forward pass to get predictions\n",
    "                outputs = self(batch_inputs.float())\n",
    "\n",
    "                # gets the predicted class (index of the maximum logit)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                # counting correct predictions\n",
    "                total += batch_outputs.size(0)  # total number of samples in the batch\n",
    "                correct += (predicted == batch_outputs).sum().item()  # counting correct predictions\n",
    "\n",
    "        accuracy = correct / total\n",
    "        return accuracy\n",
    "\n",
    "    def get_log(self):\n",
    "        \"\"\"\n",
    "        Retrieves the log text and clears the log after retrieval.\n",
    "\n",
    "        Returns:\n",
    "            str: The log text.\n",
    "        \"\"\"\n",
    "        log_copy = self.log_text\n",
    "        self.log_text = \"\"  # Clear the log after returning\n",
    "        return log_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7020067c-d22d-4d66-9ce8-6732a5429b3a",
   "metadata": {},
   "source": [
    "##### Model Loading without Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f7660cd-1f20-4d54-b712-3c21af11ed90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'model_001'\n",
    "file_path = f'trained_models/{dataset_name}_trained_models/{model_name}.pth' # where to save your trained models\n",
    "checkpoint = torch.load(file_path, map_location=\"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a36f01fc-c358-4d2e-8468-425517afa426",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layers_config': {'LogicLayer001': {'connections': 'random', 'device': 'cpu', 'grad_factor': 2, 'implementation': 'cpu', 'in_dim': 400, 'out_dim': 2500}, 'LogicLayer002': {'connections': 'random', 'device': 'cpu', 'grad_factor': 2, 'implementation': 'cpu', 'in_dim': 2500, 'out_dim': 2500}}, 'output_size': 10, 'tau': 10, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Access the layers_config part of the model_config\n",
    "layers_config = checkpoint['model_config']['layers_config']\n",
    "\n",
    "# Iterate through each layer and update 'device' and 'implementation' keys if they are 'cuda'\n",
    "for layer_name, config in layers_config.items():\n",
    "    if config.get('device') == 'cuda':\n",
    "        config['device'] = 'cpu'\n",
    "    if config.get('implementation') == 'cuda':\n",
    "        config['implementation'] = 'cpu'\n",
    "\n",
    "# Verify the changes\n",
    "loaded_config = checkpoint['model_config']\n",
    "print(loaded_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0d2e119-0582-4952-a968-cd527fc05cf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_name = 'mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4989f8fe-1211-433e-80ea-fb1d01e626bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogicLayer(400, 2500, train)\n",
      "LogicLayer(2500, 2500, train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DiffLogic(\n",
       "  (logic_layers): Sequential(\n",
       "    (0): LogicLayer(400, 2500, eval)\n",
       "    (1): LogicLayer(2500, 2500, eval)\n",
       "  )\n",
       "  (group): GroupSum(k=10, tau=10)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now reconstruct the model using the saved config\n",
    "model_reconstructed = DiffLogic(\n",
    "    layers_config=loaded_config['layers_config'],\n",
    "    output_size=loaded_config['output_size'],\n",
    "    tau=loaded_config['tau']\n",
    ")\n",
    "\n",
    "# Load the state_dict\n",
    "model_reconstructed.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# If needed, also restore the connections\n",
    "for idx, layer in enumerate(model_reconstructed.logic_layers):\n",
    "    if isinstance(layer, LogicLayer):\n",
    "        layer.indices = checkpoint['connections'][idx]\n",
    "\n",
    "model_reconstructed.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7c6f9f8-2225-4765-b073-48bde2bc5030",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Inference: 100%|██████████| 17/17 [00:07<00:00,  2.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7548253676470589"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_reconstructed.get_accuracy(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c028eea-8b4d-4332-90e4-badd96e25309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EXPLOGIC",
   "language": "python",
   "name": "explogic_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
